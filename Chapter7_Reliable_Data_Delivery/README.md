Chapter7. 신뢰성 있는 데이터 전달
---

##  이 장에서 다루는 핵심
1. 카프카에서 서로 다른 종류의 신뢰성에는 어떤 것이 있는지
2. 카프카의 복제 메커니즘이 시스템의 신뢰성에 어떤 영향이 미치는지
3. 카프카의 브로커와 토픽은 어떻게 설정해줘야 하는지
4. 시스템의 신뢰성을 검증하는 방법

## 신뢰성 보장(Guarantee) - 카프카가 제공하는 신뢰성 보장은 무엇인가?
- 파티션 안의 메시지 간에 순서를 보장한다.
- 메시지는 모든 ISR(In Sync Replica)의 파티션에 쓰여진 뒤에야 "커밋"된 것으로 간주한다.
- 컨슈머는 커밋된 메시지만 읽을 수 있다.
- 커밋된 메시지는 최소 1개의 작동하는 레플리카에 남아 있다면 유실 되지 않는다.

> [!메시지 저장 vs 성능과 비용]
> 신뢰성 있는 시스템을 구축하는 데는 트레이드오프가 있는 법이다. 
> 카프카의 트레이드오프는 메시지 저장의 신뢰성과 일관성인가, 아니면 가용성, 높은 처리량, 낮은 지연 및 하드웨어 비용이 고려사항이 될 수 있다.


## 복제 신뢰성
카프카의 복제는 파티션별로 다수의 레플리카를 유지한다는 것이 신뢰성 보장의 핵심이 된다.

### ISR(In Sync Replica)의 조건
1. 주키퍼와 최근 6초 사이 하트비트 전송을 통해 활성 세션이 유지되고 있다.
2. 최근 10초 사이에 파티션 리더로부터 가장 최근 메시지를 가져왔다.

> 동기화가 살짝 늦은 ISR이 존재한다면, 프로듀서와 컨슈머는 그만큼 지연될 수 있다.
> 왜냐하면 프로듀서와 컨슈머는 모든 ISR이 메시지를 받은 다음에야 읽거나 보낼 수 있기 때문이다.


## 브로커 설정
- 신뢰성 제어는 브로커 단위 또는 토픽 단위로도 설정할 수 있다.
	- 전체 클러스터 단위의 안정성을 중점을 둬야 할 때
	- 데이터 유실을 허용하는 특정 토픽에는 예외를 둬야 할 때


### 복제 팩터 (Replication Factor)
- 복제 팩터가 N이면 N-1의 브로커가 중단되어도 토픽의 데이터를 읽거나 쓸 수 있다.
- 이미 존재하는 토픽이라도 복제 팩터를 변경할 수 있다.
- 복제 팩터가 N이라는 것은 최소 N개의 브로커와 N배의 디스크 공간이 필요하다.
- 복제 팩터가 클수록 가용성과 하드웨어(disk) 사용량 사이에 트레이드오프가 있다는 것이다. 

### 몇 개의 레플리카를 만드는 것이 적절할까?
1. _가용성 측면_
	- 레플리카가 1개라면 브로커를 재시작하기만 해도 해당 토픽은 작동 불능이 된다.
2. _지속성 측면_
	- 레플리카가 1개라면 해당 브로커의 디스크에 문제가 생길 경우 모든 데이터가 유실된다.
3. _처리량 측면_
	- 레플리카가 늘어날수록 브로커간 트래픽도 늘어나기 때문에 클러스터 규모를 산정할 때 고려해야 한다.
4. _지연 시간 측면_
	- 컨슈머는 모든 ISR에 복제된 메시지만 읽을 수 있기 때문에 레플리카 중 하나만 느려져도 영향을 받는다.
5. _비용 측면_
	- 레플리카가 늘어날수록 저장소와 네트워크 비용도 증가한다.
6. _가용 영역 측면_
	- 토픽의 레플리카는 서로 다른 브로커에 저장된다. 같은 랙에 위치한 브로커는 해당 랙의 장애 발생시 영향을 받는다. 
	- 클라우드 환경에서는 보통 서로 다른 가용 영역(AZ, Availability Zone)에 브로커를 분산 배치한다.

### 언클린 리더 선출

> "클린한 리더 선출"이란, ISR 중에서 새 리더가 선출되는 것을 의미한다.
> 즉, 커밋된 데이터에 아무런 유실이 없음을 보장하게 된다.
> `unclean.leader.election.enable=true` 

#### 파티션 리더가 불능에 빠졌는데 ISR이 없다면 어떻게 해야 할까?
1. _Out-of Sync Replica가 새 리더가 될 수 없도록 해야 한다._
	- 예전 파티션 리더가 복구될 때까지 해당 파티션은 사용할 수 없다.
2. _Out-of Sync Replica도 새 리더가 될 수 있다._
	- 예전 파티션 리더에 쓰여졌던 메시지는 모두 유실된다.
	- 컨슈머들 사이에서는 동일한 파티션에 같은 오프셋에 대해서 전혀 다른 메시지를 읽게 되는 문제가 발생한다.
	- 예전 파티션 리더가 복구되어 새 팔로워가 된다면, 현재 파티션 리더가 갖고 있지 않은 메시지는 모두 삭제한다. 


### 최소 ISR
- 토픽 단위 또는 브로커 단위로 최소 ISR(`min.insync.replicas`)을 지정할 수 있다. 
- 즉, 토픽의 레플리카 중 **최소 몇 개의 동기화(`min.insync.replicas`)가 되어 있어야 안전하게 커밋할 수 있는지**를 결정한다.
- 만약 토픽의 가용 레플리카가 최소 ISR보다 작아지면, 브로커는 더 이상 쓰기 요청을 처리할 수 없다. (안전하게 커밋할 수 없으니까)
	- 하지만 컨슈머는 이미 커밋된 메시지에 대해서는 남아 있는 레플리카로부터 읽을 수 있다. (읽기 전용 파티션이 되는 꼴)

### Out-of Sync Replica가 될 수 있는 민감도 설정 (브로커 설정)
- `zookeeper.session.timeout.ms`
	- 브로커가 주키퍼로 하트비트 전송을 보내야 하는 최대 시간
	- 이 시간 안에만 하트비트를 보내면 주키퍼는 브로커가 살아있다고 판단한다. 
- `replica.lag.time.max.ms`
	- 레플리카가 파티션 리더로부터 데이터를 읽어와야 하는 최대 지연 시간 
	- 이 시간 안에 최신 메시지를 따라잡지 못하는 경우 Out-of Sync Replica가 된다. 

### 디스크에 저장하기
- 카프카는 레플리카 수에만 의존할 뿐, 디스크에 저장되지 않은 메시지도 응답
- 세그먼트를 교체할 때와 재시작할 때만 디스크에 Flush 하며, 그 외 경우 리눅스 페이지 캐시 기능에 의존한다.


## 신뢰성 있게 프로듀서 사용하기
### 프로듀서가 신경써야 하는 세 가지
1. 제대로 응답하기: 신뢰성 요구 조건에 올바른 `acks`설정을 사용
2. 재시도 하기
3. 설정과 코드에서 올바른 에러

### 프로듀서의 응답 모드
- `acks=0`
	- 프로듀서가 네트워크로 메시지를 전송한 시점에 성공적으로 쓰여진 것으로 간주
	- 단점
		- 파티션 오프라인, 리더 선출중, 

### 재시도 설정
- 메시지를 받은 브로커가 반환하는 에러 코드는 재시도 가능한 것과 아닌 것의 차이가 있다.
	- 예시1) `LEADER_NOT_AVAILABLE` → 재시도 가능 (조금 기다리면 리더가 재선출될 수도 있으니까)
	- 예시2) `INVALID_CONFIG` → 재시도 불가능
- 가장 좋은 방법
	1. 재시도 수를 기본 설정값(사실상 무한, MAX_INT) 그대로 둔다.
	2. 메시지 전송을 포기할 때까지 대기할 수 있는 `delivery.timeout.ms`를 최대로 설정
- 주의할 점
	- 재시도하는 것은 중복된 메시지가 브로커에 성공적으로 쓰여졌다는 의미
	- 재시도 및 에러 처리는 각 메시지가 **'최소 한 번' 저장되는 것은 보장**할 수 있다. (즉, 무조건 한 번 이상은 쓰여질 수 있다.)
	- 하지만 **'정확히 한 번'은 보장할 수 없다.**

### 에러 처리를 하는 목적을 명확하게 하라
- 가정
	- "에러가 발생해서 핸들러(callback)가 실행 되었다."
- 고려할 사항
	1. 그냥 폐기할까?
	2. 에러를 로깅할까?
	3. 그만 중단해야 할까?
	4. 잠시 전송을 멈출까?
	5. 디스크에 저장해야 할까? 
	6. 등등


## 신뢰성 있게 컨슈머 사용하기
### 신뢰성을 위한 컨슈머 설정 몇 가지
- _`group_id`_
	- 하나의 토픽을 구독하는 동일한 그룹 ID의 여러 컨슈머는 서로 다른 부분 부분의 메시지만을 읽게 된다. 
	- 특정 컨슈머가 모든 메시지를 읽어야 한다면 고유한 그룹 ID를 할당한다. 
- _`auto.offset.reset`_
	- 해당 컨슈머로부터 커밋된 오프셋이 없을 때 어디서부터 메시지를 읽을 것인가 결정
	- `earliest` : 파티션의 맨 앞에서
	- `latest` : 파티션의 끝부분에서
- _`enable.auto.commit`_
	- 자동으로 오프셋을 커밋할 것인가 하는 설정
	- 장점: 폴링 루프에서 읽어온 메시지를 처리하는 와중에도 자동 오프셋 커밋은 <u>처리하지 않은 오프셋이 커밋되지 않도록 보장</u>해준다.
	- 단점: 메시지 중복처리를 직접 제어할 수 없다.
- _`auto.commit.interval.ms`_
	- 오프셋 자동 커밋 주기
	- 기본값 5초
	- 더 짧게 할 경우 오버헤드는 늘어나지만, 컨슈머가 정지했을 때 중복 가능성이 줄어든다.

### 명시적으로 오프셋 커밋하기
#### (1) 메시지 처리 먼저, 오프셋 커밋은 나중에
- 폴링 루프 사이에 오프셋 커밋 상태를 저장할 필요가 없는 경우
	- ㄴ 자동 오프셋 커밋을 사용한다.
	- ㄴ 폴링 루프 끝에서 오프셋을 커밋한다.
	- ㄴ 일정 주기로 오프셋을 커밋한다.

#### (2) 커밋 빈도는 성능상의 오버헤드를 수반한다
- 특정 컨슈머 그룹의 모든 오프셋 커밋은 동일한 브로커로 가기 때문에 오버헤드가 될 수 있다.
- 커밋 주기와 중복 발생 가능성 사이에 균형을 맞춰야 한다. 

#### (3) 정확한 시점에 정확한 오프셋을 커밋
- <u>마지막으로 읽어온 메시지의 오프셋을 커밋하면 안 된다.</u>
- **마지막으로 처리된 메시지의 오프셋을 커밋해야 한다.**

#### (4) 컨슈머 리밸런싱이 발생할 수 있다는 사실을 염두한다
(4장 참고?)

#### (5) 컨슈머도 재시도를 할 수 있다
- `poll()`을 호출해서 가져온 메시지 중에 일부가 처리 되지 않은 상태에서 나중에 처리해야 될 경우가 생길 수 있다.
- 하지만 처리된 메시지 중에 아무거나 미리 오프셋을 커밋해버리면 해당 오프셋 이전 메시지는 모두 커밋된 것으로 간주되기 때문에 주의해야 한다. 
- 만약 나중에 처리해야 할 메시지가 있을 때 컨슈머의 `pause()`메서드를 호출해서 `poll()` 호출이 데이터를 반환하지 않도록 멈출 수 있는 점을 활용할 수 있다.

#### (6) 컨슈머 상태 유지
- 지속해서 누적된 값을 처리하는 컨슈머의 경우, 컨슈머가 재시작 되었을 때 마지막 오프셋부터 작업을 하면 누적 계산이 틀려지게 된다. 
- 오프셋을 커밋할 때 누적 값을 따로 저장하는 `results` 토픽 같은 걸 추가로 운영하는 것도 방법이다.

